{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5a34f1",
   "metadata": {},
   "source": [
    "# Prática spark\n",
    "## Objetivo\n",
    "El objetivo de esta práctica es realizar el procesado de un fichero de logs para poder\n",
    "## Práctica\n",
    "### Conexión\n",
    "El primer paso para realizar la práctica es establecer la conexión con el cluster de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a7aa558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/16 14:30:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from  pyspark.sql.functions import col, concat_ws,split, explode ,desc, to_timestamp,from_unixtime,unix_timestamp, translate, create_map, lit,udf,StringType,map_keys\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6992ec0a",
   "metadata": {},
   "source": [
    "### Lectura\n",
    "Una vez que se ha establecido la conexión con el cluster de spark, es necesario cargar el archivo de texto que se va a tratar.\n",
    "Para esta práctica se va a leer como un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b105b57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               datos|\n",
      "+--------------------+\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "|01-11-2022 13:24:...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ficheroDataframe = spark.read.text(\"logs.txt\")\n",
    "ficheroDataFrameRenamed = ficheroDataframe.withColumnRenamed(\"value\",\"datos\")\n",
    "# Se muestran los primeros 20 elementos\n",
    "ficheroDataFrameRenamed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7b3d27",
   "metadata": {},
   "source": [
    "### Preprocesado\n",
    "Una vez que se ha cargado el fichero, será necesario dividir la columna por el carácter \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403ce734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datos: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ficheroDataFrameSplit = ficheroDataFrameRenamed.select(split(col(\"datos\"),\" - \"))\n",
    "ficheroDataFrameSplit = ficheroDataFrameSplit.withColumnRenamed(\"split(datos,  - , -1)\",\"datos\")\n",
    "\n",
    "ficheroDataFrameSplit.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99090d26",
   "metadata": {},
   "source": [
    "Se construye el dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2847a90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------+--------------------+\n",
      "|              Fecha|     Log|Module|                Info|\n",
      "+-------------------+--------+------+--------------------+\n",
      "|01-11-2022 13:24:13|    INFO|pandas|Aliquam amet adip...|\n",
      "|01-11-2022 13:24:17| WARNING| spark|Consectetur velit...|\n",
      "|01-11-2022 13:24:20| WARNING|pandas|Porro etincidunt ...|\n",
      "|01-11-2022 13:24:22|   ERROR|pandas|Tempora modi quiq...|\n",
      "|01-11-2022 13:24:24| WARNING| spark|Quiquia etincidun...|\n",
      "|01-11-2022 13:24:25|    INFO| spark|Non est porro por...|\n",
      "|01-11-2022 13:24:26|CRITICAL|python|Porro labore eius...|\n",
      "|01-11-2022 13:24:28|CRITICAL| numpy|Est ut tempora se...|\n",
      "|01-11-2022 13:24:29|    INFO| spark|Sit dolorem dolor...|\n",
      "|01-11-2022 13:24:30|CRITICAL| spark|Etincidunt aliqua...|\n",
      "|01-11-2022 13:24:31|   DEBUG|python|Aliquam sed porro...|\n",
      "|01-11-2022 13:24:32|CRITICAL| numpy|Numquam dolor ips...|\n",
      "|01-11-2022 13:24:33|CRITICAL|python|Amet neque est ip...|\n",
      "|01-11-2022 13:24:34|   DEBUG|python|Eius ut tempora i...|\n",
      "|01-11-2022 13:24:35| WARNING| spark|Quiquia numquam s...|\n",
      "|01-11-2022 13:24:36|   ERROR| numpy|Quisquam adipisci...|\n",
      "|01-11-2022 13:24:37|CRITICAL| spark|Voluptatem dolor ...|\n",
      "|01-11-2022 13:24:38|CRITICAL| spark| Dolor neque ut non.|\n",
      "|01-11-2022 13:24:39|   DEBUG| numpy|Tempora adipisci ...|\n",
      "|01-11-2022 13:24:40|   ERROR| numpy|Velit numquam dol...|\n",
      "+-------------------+--------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dataFrameDatos= ficheroDataFrameSplit.select(col(\"datos\").getItem(0),col(\"datos\").getItem(1),col(\"datos\").getItem(2),col(\"datos\").getItem(3))\n",
    "# Se renombran las columnas\n",
    "dataFrameDatos = dataFrameDatos.withColumnRenamed(\"datos[0]\",\"Fecha\")\n",
    "dataFrameDatos = dataFrameDatos.withColumnRenamed(\"datos[1]\",\"Log\")\n",
    "dataFrameDatos = dataFrameDatos.withColumnRenamed(\"datos[2]\",\"Module\")\n",
    "dataFrameDatos = dataFrameDatos.withColumnRenamed(\"datos[3]\",\"Info\")\n",
    "dataFrameDatos.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a0ccf8",
   "metadata": {},
   "source": [
    "Ahora se tiene el dataframe con los datos separados por columnas, se tiene que transformar la fecha a timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71d16e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------+--------------------+\n",
      "|              Fecha|     Log|Module|                Info|\n",
      "+-------------------+--------+------+--------------------+\n",
      "|2022-11-01 13:24:13|    INFO|pandas|Aliquam amet adip...|\n",
      "|2022-11-01 13:24:17| WARNING| spark|Consectetur velit...|\n",
      "|2022-11-01 13:24:20| WARNING|pandas|Porro etincidunt ...|\n",
      "|2022-11-01 13:24:22|   ERROR|pandas|Tempora modi quiq...|\n",
      "|2022-11-01 13:24:24| WARNING| spark|Quiquia etincidun...|\n",
      "|2022-11-01 13:24:25|    INFO| spark|Non est porro por...|\n",
      "|2022-11-01 13:24:26|CRITICAL|python|Porro labore eius...|\n",
      "|2022-11-01 13:24:28|CRITICAL| numpy|Est ut tempora se...|\n",
      "|2022-11-01 13:24:29|    INFO| spark|Sit dolorem dolor...|\n",
      "|2022-11-01 13:24:30|CRITICAL| spark|Etincidunt aliqua...|\n",
      "|2022-11-01 13:24:31|   DEBUG|python|Aliquam sed porro...|\n",
      "|2022-11-01 13:24:32|CRITICAL| numpy|Numquam dolor ips...|\n",
      "|2022-11-01 13:24:33|CRITICAL|python|Amet neque est ip...|\n",
      "|2022-11-01 13:24:34|   DEBUG|python|Eius ut tempora i...|\n",
      "|2022-11-01 13:24:35| WARNING| spark|Quiquia numquam s...|\n",
      "|2022-11-01 13:24:36|   ERROR| numpy|Quisquam adipisci...|\n",
      "|2022-11-01 13:24:37|CRITICAL| spark|Voluptatem dolor ...|\n",
      "|2022-11-01 13:24:38|CRITICAL| spark| Dolor neque ut non.|\n",
      "|2022-11-01 13:24:39|   DEBUG| numpy|Tempora adipisci ...|\n",
      "|2022-11-01 13:24:40|   ERROR| numpy|Velit numquam dol...|\n",
      "+-------------------+--------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- Fecha: timestamp (nullable = true)\n",
      " |-- Log: string (nullable = true)\n",
      " |-- Module: string (nullable = true)\n",
      " |-- Info: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataFrameDatos = dataFrameDatos.withColumn(\"Fecha\",to_timestamp(col(\"Fecha\"),\"dd-MM-yyyy HH:mm:ss\"))\n",
    "dataFrameDatos.show()\n",
    "dataFrameDatos.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d0930e",
   "metadata": {},
   "source": [
    "Por último va a ser necesario realilzar un mapeo entre el nivel de incidencia y in valor numérico previamente establecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dde117b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------+--------------------+---+\n",
      "|              Fecha|     Log|Module|                Info|Map|\n",
      "+-------------------+--------+------+--------------------+---+\n",
      "|2022-11-01 13:24:13|    INFO|pandas|Aliquam amet adip...| 20|\n",
      "|2022-11-01 13:24:17| WARNING| spark|Consectetur velit...| 30|\n",
      "|2022-11-01 13:24:20| WARNING|pandas|Porro etincidunt ...| 30|\n",
      "|2022-11-01 13:24:22|   ERROR|pandas|Tempora modi quiq...| 40|\n",
      "|2022-11-01 13:24:24| WARNING| spark|Quiquia etincidun...| 30|\n",
      "|2022-11-01 13:24:25|    INFO| spark|Non est porro por...| 20|\n",
      "|2022-11-01 13:24:26|CRITICAL|python|Porro labore eius...| 50|\n",
      "|2022-11-01 13:24:28|CRITICAL| numpy|Est ut tempora se...| 50|\n",
      "|2022-11-01 13:24:29|    INFO| spark|Sit dolorem dolor...| 20|\n",
      "|2022-11-01 13:24:30|CRITICAL| spark|Etincidunt aliqua...| 50|\n",
      "|2022-11-01 13:24:31|   DEBUG|python|Aliquam sed porro...| 10|\n",
      "|2022-11-01 13:24:32|CRITICAL| numpy|Numquam dolor ips...| 50|\n",
      "|2022-11-01 13:24:33|CRITICAL|python|Amet neque est ip...| 50|\n",
      "|2022-11-01 13:24:34|   DEBUG|python|Eius ut tempora i...| 10|\n",
      "|2022-11-01 13:24:35| WARNING| spark|Quiquia numquam s...| 30|\n",
      "|2022-11-01 13:24:36|   ERROR| numpy|Quisquam adipisci...| 40|\n",
      "|2022-11-01 13:24:37|CRITICAL| spark|Voluptatem dolor ...| 50|\n",
      "|2022-11-01 13:24:38|CRITICAL| spark| Dolor neque ut non.| 50|\n",
      "|2022-11-01 13:24:39|   DEBUG| numpy|Tempora adipisci ...| 10|\n",
      "|2022-11-01 13:24:40|   ERROR| numpy|Velit numquam dol...| 40|\n",
      "+-------------------+--------+------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_mapping = {\n",
    "    'CRITICAL': 50,\n",
    "    'ERROR': 40,\n",
    "    'WARNING': 30,\n",
    "    'INFO': 20,\n",
    "    'DEBUG': 10, \n",
    "    'NOTSET': 0}\n",
    "log_mapping_spark = create_map([lit(x) for x in chain(*log_mapping.items())])\n",
    "\n",
    "dataFrameDatos = dataFrameDatos.withColumn(\"Map\",log_mapping_spark[col(\"Log\")])\n",
    "dataFrameDatos.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f443503",
   "metadata": {},
   "source": [
    "### Filtrado por módulo\n",
    "Con el dataframe preprocesado como se desea, se va a comenzar a extraer información.\n",
    "En un inicio se van a extraer las filas que coincidan con un valor de módulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdffce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------+--------------------+---+\n",
      "|              Fecha|     Log|Module|                Info|Map|\n",
      "+-------------------+--------+------+--------------------+---+\n",
      "|2022-11-01 13:24:17| WARNING| spark|Consectetur velit...| 30|\n",
      "|2022-11-01 13:24:24| WARNING| spark|Quiquia etincidun...| 30|\n",
      "|2022-11-01 13:24:25|    INFO| spark|Non est porro por...| 20|\n",
      "|2022-11-01 13:24:29|    INFO| spark|Sit dolorem dolor...| 20|\n",
      "|2022-11-01 13:24:30|CRITICAL| spark|Etincidunt aliqua...| 50|\n",
      "|2022-11-01 13:24:35| WARNING| spark|Quiquia numquam s...| 30|\n",
      "|2022-11-01 13:24:37|CRITICAL| spark|Voluptatem dolor ...| 50|\n",
      "|2022-11-01 13:24:38|CRITICAL| spark| Dolor neque ut non.| 50|\n",
      "|2022-11-01 13:24:51|   DEBUG| spark|Modi est modi non...| 10|\n",
      "|2022-11-01 13:24:51| WARNING| spark|Magnam numquam ut...| 30|\n",
      "|2022-11-01 13:24:51|   DEBUG| spark|Modi quiquia cons...| 10|\n",
      "|2022-11-01 13:24:51|    INFO| spark|Neque adipisci ma...| 20|\n",
      "|2022-11-01 13:24:51| WARNING| spark|Velit numquam neq...| 30|\n",
      "|2022-11-01 13:24:51|   DEBUG| spark|Quaerat magnam se...| 10|\n",
      "|2022-11-01 13:24:51| WARNING| spark|Est modi sit nequ...| 30|\n",
      "|2022-11-01 13:24:51|   DEBUG| spark|Sit ipsum quiquia...| 10|\n",
      "|2022-11-01 13:24:51| WARNING| spark|Quisquam amet adi...| 30|\n",
      "|2022-11-01 13:24:51|   ERROR| spark|Porro dolorem sit...| 40|\n",
      "|2022-11-01 13:24:51|   DEBUG| spark|Dolor sed etincid...| 10|\n",
      "|2022-11-01 13:24:51| WARNING| spark|Non magnam volupt...| 30|\n",
      "+-------------------+--------+------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modulo = \"spark\"\n",
    "resultado = dataFrameDatos.filter(modulo== col(\"Module\"))\n",
    "resultado.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788552bd",
   "metadata": {},
   "source": [
    "### Filtrado por palabra en string\n",
    "En este apartado se va filtrar si una palabra se encuentra en el campo de información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c43bc5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------+--------------------+---+\n",
      "|              Fecha|     Log|Module|                Info|Map|\n",
      "+-------------------+--------+------+--------------------+---+\n",
      "|2022-11-01 13:24:20| WARNING|pandas|Porro etincidunt ...| 30|\n",
      "|2022-11-01 13:24:26|CRITICAL|python|Porro labore eius...| 50|\n",
      "|2022-11-01 13:24:51|   ERROR| numpy|Porro est neque n...| 40|\n",
      "|2022-11-01 13:24:51|   ERROR| spark|Porro dolorem sit...| 40|\n",
      "|2022-11-01 13:24:51|   ERROR|pandas|Porro ipsum conse...| 40|\n",
      "|2022-11-01 13:24:51|CRITICAL| spark|Porro eius consec...| 50|\n",
      "|2022-11-01 13:24:51|CRITICAL|pandas|Porro amet sed mo...| 50|\n",
      "|2022-11-01 13:24:51|CRITICAL|pandas|Porro modi non qu...| 50|\n",
      "|2022-11-01 13:24:51|    INFO|python|Porro modi aliqua...| 20|\n",
      "|2022-11-01 13:24:51|   DEBUG|pandas|Porro amet sit la...| 10|\n",
      "|2022-11-01 13:24:51|   DEBUG|pandas|Porro quiquia dol...| 10|\n",
      "|2022-11-01 13:24:51|    INFO|pandas|Porro tempora adi...| 20|\n",
      "|2022-11-01 13:24:51|   DEBUG| spark|Porro sed dolore ...| 10|\n",
      "|2022-11-01 13:24:51|   DEBUG| numpy|Porro quiquia ali...| 10|\n",
      "|2022-11-01 13:24:51|    INFO|pandas|Porro ipsum amet ...| 20|\n",
      "|2022-11-01 13:24:51|CRITICAL|python|Porro porro aliqu...| 50|\n",
      "|2022-11-01 13:24:51|    INFO| spark|Porro tempora qui...| 20|\n",
      "|2022-11-01 13:24:51|   ERROR| numpy|Porro sit quisqua...| 40|\n",
      "|2022-11-01 13:24:51|CRITICAL|pandas|Porro dolore veli...| 50|\n",
      "|2022-11-01 13:24:51|CRITICAL| numpy|Porro ut adipisci...| 50|\n",
      "+-------------------+--------+------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "palabra = \"Porro\"\n",
    "resultado = dataFrameDatos.filter(col(\"Info\").contains(palabra))\n",
    "resultado.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44cbfad",
   "metadata": {},
   "source": [
    "### Filtrado por input de palabra\n",
    "Se van a mostrar las filas que tengan un nivel de incidencia igual o superior que el nivel solicitado. De esta forma si se introduce como nivel mínimo \"Warning\", se deberían de mostrar las filas con niveles \"Warning\", \"Error\" y \"Critical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8f44870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------+--------------------+---+\n",
      "|              Fecha|     Log|Module|                Info|Map|\n",
      "+-------------------+--------+------+--------------------+---+\n",
      "|2022-11-01 13:24:17| WARNING| spark|Consectetur velit...| 30|\n",
      "|2022-11-01 13:24:20| WARNING|pandas|Porro etincidunt ...| 30|\n",
      "|2022-11-01 13:24:22|   ERROR|pandas|Tempora modi quiq...| 40|\n",
      "|2022-11-01 13:24:24| WARNING| spark|Quiquia etincidun...| 30|\n",
      "|2022-11-01 13:24:26|CRITICAL|python|Porro labore eius...| 50|\n",
      "|2022-11-01 13:24:28|CRITICAL| numpy|Est ut tempora se...| 50|\n",
      "|2022-11-01 13:24:30|CRITICAL| spark|Etincidunt aliqua...| 50|\n",
      "|2022-11-01 13:24:32|CRITICAL| numpy|Numquam dolor ips...| 50|\n",
      "|2022-11-01 13:24:33|CRITICAL|python|Amet neque est ip...| 50|\n",
      "|2022-11-01 13:24:35| WARNING| spark|Quiquia numquam s...| 30|\n",
      "|2022-11-01 13:24:36|   ERROR| numpy|Quisquam adipisci...| 40|\n",
      "|2022-11-01 13:24:37|CRITICAL| spark|Voluptatem dolor ...| 50|\n",
      "|2022-11-01 13:24:38|CRITICAL| spark| Dolor neque ut non.| 50|\n",
      "|2022-11-01 13:24:40|   ERROR| numpy|Velit numquam dol...| 40|\n",
      "|2022-11-01 13:24:41|CRITICAL|pandas|Voluptatem quaera...| 50|\n",
      "|2022-11-01 13:24:41| WARNING|pandas|Voluptatem dolore...| 30|\n",
      "|2022-11-01 13:24:42|CRITICAL|pandas|Velit quiquia ali...| 50|\n",
      "|2022-11-01 13:24:42|CRITICAL|python|Sed adipisci cons...| 50|\n",
      "|2022-11-01 13:24:51| WARNING| spark|Magnam numquam ut...| 30|\n",
      "|2022-11-01 13:24:51|CRITICAL|python|Quaerat labore al...| 50|\n",
      "+-------------------+--------+------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nivel = \"WARNING\"\n",
    "\n",
    "# Primero se obtiene el valor numérico para el nivel\n",
    "valor = log_mapping[nivel]\n",
    "\n",
    "resultado = dataFrameDatos.filter(valor <= col(\"Map\"))\n",
    "resultado.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd0a107",
   "metadata": {},
   "source": [
    "### Filtrado por fecha\n",
    "Se filtra para obtener todas las entradas del log posteriores al valor de fecha establecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1978033e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------+--------------------+---+\n",
      "|              Fecha|     Log|Module|                Info|Map|\n",
      "+-------------------+--------+------+--------------------+---+\n",
      "|2022-11-01 13:24:42|   DEBUG|pandas|Aliquam modi magn...| 10|\n",
      "|2022-11-01 13:24:42|CRITICAL|pandas|Velit quiquia ali...| 50|\n",
      "|2022-11-01 13:24:42|CRITICAL|python|Sed adipisci cons...| 50|\n",
      "|2022-11-01 13:24:51|   DEBUG| spark|Modi est modi non...| 10|\n",
      "|2022-11-01 13:24:51|   DEBUG|pandas|Ut consectetur ei...| 10|\n",
      "|2022-11-01 13:24:51| WARNING| spark|Magnam numquam ut...| 30|\n",
      "|2022-11-01 13:24:51|CRITICAL|python|Quaerat labore al...| 50|\n",
      "|2022-11-01 13:24:51|   ERROR|pandas|Quaerat modi non ...| 40|\n",
      "|2022-11-01 13:24:51|   ERROR|pandas|Est ipsum tempora...| 40|\n",
      "|2022-11-01 13:24:51|   DEBUG|python|Quaerat ipsum est...| 10|\n",
      "|2022-11-01 13:24:51|    INFO|pandas|Modi quisquam num...| 20|\n",
      "|2022-11-01 13:24:51|   DEBUG|python|Velit sed quiquia...| 10|\n",
      "|2022-11-01 13:24:51| WARNING| numpy|Consectetur adipi...| 30|\n",
      "|2022-11-01 13:24:51|   ERROR|python|Amet quisquam ut ...| 40|\n",
      "|2022-11-01 13:24:51|CRITICAL|pandas|Sit tempora quaer...| 50|\n",
      "|2022-11-01 13:24:51|   ERROR| numpy|Porro est neque n...| 40|\n",
      "|2022-11-01 13:24:51| WARNING| numpy|Dolore quaerat ve...| 30|\n",
      "|2022-11-01 13:24:51|   DEBUG| spark|Modi quiquia cons...| 10|\n",
      "|2022-11-01 13:24:51| WARNING|python|Dolorem quaerat v...| 30|\n",
      "|2022-11-01 13:24:51|   ERROR|pandas|Amet etincidunt m...| 40|\n",
      "+-------------------+--------+------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "after = datetime.strptime('11/01/22 13:24:41', '%m/%d/%y %H:%M:%S')\n",
    "\n",
    "resultado = dataFrameDatos.filter(col(\"Fecha\") >(after)) \n",
    "resultado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c768de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
